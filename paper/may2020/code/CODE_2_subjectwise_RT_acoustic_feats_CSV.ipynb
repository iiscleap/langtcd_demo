{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Make CSV with subjectwise trial details, RT, and acoustic feature distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "sns.set() # Use seaborn's default style to make attractive graphs\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Init paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_wav_files = './lisTest/tcdDecision/playback/STIMULI/'\n",
    "wav_folder_types = ['chinese','english']\n",
    "file_types = ['nspkrs_1','nspkrs_2']\n",
    "\n",
    "path_store_feats = './dataAnalysis/data/feats/PRAAT/'\n",
    "path_store_figure = './figures/'\n",
    "# make direcs if absent\n",
    "if not os.path.exists(path_store_feats):\n",
    "    os.mkdir(path_store_feats)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Read listening test stimulus set filenames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read wav filenames with path\n",
    "wav_files = []\n",
    "for i in range(len(wav_folder_types)):\n",
    "    wav_files.append([])\n",
    "    for j in range(len(file_types)):\n",
    "        wav_files[i].append([])\n",
    "        for file in glob.glob(path_wav_files+wav_folder_types[i]+'/wavFilesTest/'+'*'+file_types[j]+'.wav'):\n",
    "            wav_files[i][j].append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Read stimulus feature pickle file and compute the feature distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# euclidean distance\n",
    "feats_column_name = ['pitch','mfcc', 'mel','scentroid','harm','intensity','xvec']\n",
    "\n",
    "\n",
    "feats_distance = []\n",
    "feats_distance.append([])\n",
    "feats_distance[0].append('fname')\n",
    "feats_distance[0].append('lang')\n",
    "feats_distance[0].append('changeIns')\n",
    "for i in range(len(feats_column_name)):\n",
    "    feats_distance[0].append(feats_column_name[i])\n",
    "cnt = 1\n",
    "for i in range(len(wav_files)):\n",
    "    for j in range(len(wav_files[i])):\n",
    "        for k in range(len(wav_files[i][j])):\n",
    "            feats_distance.append([])\n",
    "            head, tail = os.path.split(wav_files[i][j][k])\n",
    "\n",
    "            # load pickle file\n",
    "            with open(path_store_feats+tail[:-4]+'.pickle', 'rb') as f:\n",
    "                feats = pickle.load(f) \n",
    "            \n",
    "            feats_distance[cnt].append(tail[:-4])\n",
    "            feats_distance[cnt].append(i)\n",
    "            changeIns = float(tail.split('_nspkrs')[0].split('_')[-2]+\\\n",
    "                                    '.'+tail.split('_nspkrs')[0].split('_')[-1])\n",
    "            feats_distance[cnt].append(changeIns)\n",
    "            \n",
    "            # find euclidean distance\n",
    "            for feats_name in feats_column_name:\n",
    "                if feats_name!='xvec':\n",
    "                    temp_1 = feats[feats_name+'_1'][feats['voiced_1']]\n",
    "                    temp_2 = feats[feats_name+'_2'][feats['voiced_2']]\n",
    "#                     X = np.vstack((temp_1,temp_2))\n",
    "#                     y = np.vstack((0*np.ones((temp_1.shape[0],1)),np.ones((temp_2.shape[0],1))))[:,0]\n",
    "#                     lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "#                     X_p = lda.fit(X, y).transform(X)\n",
    "#                     inter_class_scatter = np.linalg.norm(np.mean(X_p[y == 0, 0]) - np.mean(X_p[y == 1, 0]))**2 \n",
    "#                     intra_class_scatter = np.sum(np.var(X_p[y == 0, 0])+ np.var(X_p[y == 1, 0]))\n",
    "#                     dist = inter_class_scatter/intra_class_scatter\n",
    "                    temp_1 = np.mean(temp_1,axis=0)\n",
    "                    temp_2 = np.mean(temp_2,axis=0)\n",
    "                    dist = np.linalg.norm(temp_1-temp_2)\n",
    "                if feats_name == 'xvec':\n",
    "                    dist = np.linalg.norm(feats[feats_name+'_1']-feats[feats_name+'_2'])\n",
    "                feats_distance[cnt].append(dist)\n",
    "            cnt = cnt+1\n",
    "df = pd.DataFrame(feats_distance)\n",
    "new_header = df.iloc[0] #grab the first row for the header\n",
    "df = df[1:] #take the data less the header row\n",
    "df.columns = new_header #set the header row as the df header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Read and append the response CSV of each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "audio_type = ['chin','eng']\n",
    "sub_IDs = ['S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14','S15',\n",
    "          'S16','S17','S18','S19','S20','S21','S22','S23','S24','S25','S26','S27','S28','S29']\n",
    "\n",
    "miss = []\n",
    "fa = []\n",
    "hit = []\n",
    "rt_miss = []\n",
    "rt_fa = []\n",
    "rt_hit = []\n",
    "\n",
    "fa_names = []\n",
    "miss_names = []\n",
    "hit_names = []\n",
    "rt_correct = []\n",
    "rt_incorrect = []\n",
    "\n",
    "df = pd.DataFrame() \n",
    "\n",
    "for i in range(len(sub_IDs)):\n",
    "    for j in range(len(audio_type)):\n",
    "        if 1: # read from local repo\n",
    "            url = './lisTest/tcdDecision/recordings/New_recordings/'+audio_type[j]+'_'+sub_IDs[i]+'/keys.csv'\n",
    "        else: # read from online repo\n",
    "            url = 'https://raw.githubusercontent.com/neerajww/lang_tcd/venkat201097-test1/code/lisTest/tcdDecision/recordings/New_recordings/'+audio_type[j]+'_'+sub_IDs[i]+'/keys.csv'\n",
    "        # load csv into a dataframe\n",
    "        temp = pd.read_csv(url,header=None)\n",
    "        temp['subID'] = i+1\n",
    "        df = df.append(temp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Make a CSV pooling all subject response data and corresponding stimulus-wise feature distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF = df.copy()\n",
    "for i in range(len(feats_column_name)):\n",
    "    DF[feats_column_name[i]] = 0\n",
    "DF['lang'] = 0\n",
    "DF['changeIns'] = 0\n",
    "\n",
    "for i in range(len(DF)):\n",
    "    for j in range(len(feats_distance)):\n",
    "        fname = DF[1].values[i]\n",
    "        head, tail = os.path.split(fname)\n",
    "        if feats_distance[j][0] == tail[:-4]:\n",
    "            for k in range(len(feats_column_name)):\n",
    "                DF.loc[i,feats_column_name[k]] = feats_distance[j][3+k] \n",
    "            DF.loc[i,'lang'] = feats_distance[j][1] \n",
    "            DF.loc[i,'changeIns'] = feats_distance[j][2]\n",
    "DF.rename(columns={0: \"fIndex\", 1: \"fname\",2:'label',3:'response',4:'session',5:'t_start',6:\"t_end\",7:\"t_resp\"},\n",
    "          inplace = True)\n",
    "# save csv\n",
    "DF.to_csv('./dataAnalysis/data/csvs/praat_pooled_subject_response_acoustic_feats_data_euc.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
